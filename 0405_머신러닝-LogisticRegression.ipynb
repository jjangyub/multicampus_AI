{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa60300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BInary Classificatio의 대표적인 2개의 문제를 한번 구현해보자\n",
    "# 1. 위스콘신 유방암 데이터\n",
    "# 2. Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fea4358",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "(569, 30) (569,)\n",
      "(array([0, 1]), array([212, 357], dtype=int64))\n",
      "(455, 30) (455,)\n",
      "(array([0, 1]), array([170, 285], dtype=int64))\n",
      "[0.92982456 0.93859649 0.95614035 0.92982456 0.96460177]\n",
      "0.943797546964757\n",
      "0.9736842105263158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeop\\.conda\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\yeop\\.conda\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\yeop\\.conda\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\yeop\\.conda\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\yeop\\.conda\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\yeop\\.conda\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# 위스콘신 유방암 데이터\n",
    "# 이 데이터는 sklearn이 제공\n",
    "# sklearn과 tensorflow를 이용함\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model   # LogisticRegression()\n",
    "from sklearn.datasets import load_breast_cancer  # 데이터 로딩을 위한 함수\n",
    "from sklearn.model_selection import train_test_split  # 학습데이터와 평가데이터로 분리\n",
    "from sklearn.model_selection import cross_val_score  # cross_validation 하기 위해 필요\n",
    "\n",
    "# raw data loading\n",
    "# cancer = load_breast_cancer()\n",
    "print(type(cancer))  # <class 'sklearn.utils.Bunch'>\n",
    "                     # sklearn이 데이터를 표현하기 위해 사용하는 자료구조\n",
    "                     # python의 dictionary와 유사한 구조\n",
    "# print(cancer)\n",
    "# data라는 속성과 target이라는 속성을 가지고 있고\n",
    "# data라는 속성이 독립변수, target이 종속변수\n",
    "\n",
    "print(cancer.data.shape, cancer.target.shape)  # (569, 30) (569,)\n",
    "print(np.unique(cancer.target, return_counts=True))\n",
    "# array([0, 1]), array([212, 357]\n",
    "\n",
    "# 유방암 데이터에 대한 상세 내용\n",
    "# print(cancer.DESCR)\n",
    "# :Missing Attribute Values: None\n",
    "# WDBC-Malignant(악성)-0, WDBC-Benign(정상)-1\n",
    "# Class Distribution: 212 - Malignant, 357 - Benign\n",
    "\n",
    "# data set\n",
    "x_data = cancer.data\n",
    "t_data = cancer.target\n",
    "\n",
    "# Hold-out validation을 위해서 train, validation으로 분리\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(x_data,\n",
    "                 t_data,\n",
    "                 test_size = 0.2,\n",
    "                 random_state=2,\n",
    "                 stratify=t_data)\n",
    "print(train_x_data.shape, train_t_data.shape)  # (455, 30) (455,)\n",
    "print(np.unique(train_t_data, return_counts=True))\n",
    "# (array([0, 1]), array([170, 285]\n",
    "\n",
    "# Model 생성\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "# K-Fold cross validation\n",
    "test_score = cross_val_score(model, x_data, t_data, scoring='accuracy', cv=5)\n",
    "print(test_score)  # [0.92982456 0.93859649 0.95614035 0.92982456 0.96460177]\n",
    "print(test_score.mean())  # 0.943797546964757 (확률이 94프로라는것)\n",
    "\n",
    "# Hold-out 방식으로 validation\n",
    "model.fit(train_x_data, train_t_data)\n",
    "test_score = model.score(test_x_data, test_t_data)  # 따로 옵션을 주지않으면 score는 accuracy를 구함\n",
    "print(test_score)  # 0.9736842105263158\n",
    "\n",
    "# sklearn 방식을 이용해보았음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6b90978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value : 146.30230712890625\n",
      "loss value : 0.3728635609149933\n",
      "loss value : 0.3494783043861389\n",
      "loss value : 0.34985828399658203\n",
      "loss value : 0.34732216596603394\n",
      "loss value : 0.34367385506629944\n",
      "loss value : 0.3396242558956146\n",
      "loss value : 0.33554983139038086\n",
      "loss value : 0.33155977725982666\n",
      "loss value : 0.32773149013519287\n"
     ]
    }
   ],
   "source": [
    "# 위의 데이터를 tensorflow로 구현\n",
    "import tensorflow as tf\n",
    "\n",
    "# tensorflow 그래프를 그려보자\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,30], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([30,1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# Hypothesis, model, predict model, Logistic Regression Model\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# cross entropy(loss function)\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                              labels=T))\n",
    "\n",
    "# 한번 수행하면 W,b가 한번씩 좋아짐, 여러번 반복하면 여러번 좋아짐\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())  # 초기화 작업\n",
    "\n",
    "# 반복학습\n",
    "# 전체 데이터를 이용해서 1번 학습 => 1 epoch(에폭)\n",
    "for step in range(100000):\n",
    "    # train 노드랑 loss 노드 실행\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X: train_x_data,\n",
    "                                                     T: train_t_data.reshape(-1,1)})\n",
    "    # train_t_data는 1차원인데 위에서 T를 2차원으로 잡아놨으니 맞춰야함\n",
    "    \n",
    "    if step % 10000 == 0:\n",
    "        print('loss value : {}'.format(loss_val))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80d2dacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9649122953414917\n"
     ]
    }
   ],
   "source": [
    "# 정확도(accuracy) 측정\n",
    "\n",
    "# validation data(test_x_data, test_t_data)를 이용해서 정확도를 측정\n",
    "predict = tf.cast(H >= 0.5, dtype=tf.float32)  # True -> 1.0\n",
    "                                                # False -> 0.0\n",
    "# 예측값과 입력받은 정답이 일치하는지\n",
    "correct = tf.equal(predict, T)       # True, False, False, True, ...\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))   # 1, 0, 0, 1\n",
    "\n",
    "accuracy_val = sess.run(accuracy, feed_dict={X : test_x_data,\n",
    "                                             T : test_t_data.reshape(-1,1)})\n",
    "print('Accuracy : {}'.format(accuracy_val))  # 0.9649122953414917"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fca3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic 예제로 Logistic Regression 구현\n",
    "# 케글에서 데이터셋을 받아서 나온 결과를 kaggle에 업로드해서\n",
    "# 우리 모델의 정확도를 평가받아 보자!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-machine_TF15]",
   "language": "python",
   "name": "conda-env-.conda-machine_TF15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
