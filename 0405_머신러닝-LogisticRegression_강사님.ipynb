{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e0466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Classification의 대표적인 2개의 문제를 한번 구현해 보아요!\n",
    "# 1. 위스콘신 유방암 데이터\n",
    "# 2. Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "875d512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92982456 0.93859649 0.95614035 0.9122807  0.95575221]\n",
      "0.9385188635305075\n",
      "0.9736842105263158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\campusseven02\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\campusseven02\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\campusseven02\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\campusseven02\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\campusseven02\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\campusseven02\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# 위스콘신 유방암 데이터를 가지고 구현해보아요!\n",
    "# 이 데이터는 sklearn이 제공하는 데이터를 사용할 꺼예요!\n",
    "# sklearn과 tensorflow를 이용해서 구현해 보아요!\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model   # LogisticRegression()\n",
    "from sklearn.datasets import load_breast_cancer  # 데이터 로딩하기 위한 함수\n",
    "from sklearn.model_selection import train_test_split  # 학습데이터와 평가데이터 분리\n",
    "from sklearn.model_selection import cross_val_score  # cross validation하기 위해 필요\n",
    "\n",
    "# Raw Data Loading\n",
    "cancer = load_breast_cancer()\n",
    "# print(type(cancer))   # <class 'sklearn.utils.Bunch'>\n",
    "                      # sklearn이 데이터를 표현하기 위해 사용하는 자료구조.\n",
    "                      # python의 dictionary와 유사한 구조.\n",
    "# print(cancer)      \n",
    "# data라는 속성과 target이라는 속성을 가지고 있고\n",
    "# data라는 속성이 독립변수, target이 종속변수\n",
    "# print(cancer.data.shape, cancer.target.shape)  # (569, 30) (569,)\n",
    "\n",
    "# print(np.unique(cancer.target, return_counts=True))  \n",
    "# array([0, 1]), array([212, 357]\n",
    "# print(cancer.DESCR)  # 유방암 데이터에 대한 상세 내용!\n",
    "# :Missing Attribute Values: None\n",
    "# :Class Distribution: 212 - Malignant(악성), 357 - Benign(정상)\n",
    "\n",
    "# Data Set\n",
    "x_data = cancer.data\n",
    "t_data = cancer.target\n",
    "\n",
    "# Hold-out validation을 위해서 train과 validation데이터를 분리\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(x_data,\n",
    "                 t_data,\n",
    "                 test_size=0.2,\n",
    "                 random_state=2,\n",
    "                 stratify=t_data)\n",
    "# print(train_x_data.shape, train_t_data.shape)  # (455, 30) (455,)\n",
    "# print(np.unique(train_t_data, return_counts=True)) \n",
    "# array([0, 1]), array([170, 285])\n",
    "\n",
    "# Model 생성\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "# K-Fold cross validation\n",
    "test_score = cross_val_score(model, x_data, t_data, scoring='accuracy', cv=5)\n",
    "print(test_score)  # [0.92982456 0.93859649 0.95614035 0.9122807  0.95575221]\n",
    "print(test_score.mean())   # 0.9385188635305075\n",
    "\n",
    "# Hold-out 방식으로 validation\n",
    "model.fit(train_x_data, train_t_data)\n",
    "test_score = model.score(test_x_data, test_t_data)\n",
    "print(test_score)  # 0.9736842105263158\n",
    "\n",
    "# sklearn으로 구현해 보았어요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "610b3276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\campusseven02\\AppData\\Local\\Temp\\ipykernel_10044\\3753786471.py:7: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\campusseven02\\anaconda3\\envs\\machine_TF15\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\campusseven02\\AppData\\Local\\Temp\\ipykernel_10044\\3753786471.py:23: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\campusseven02\\AppData\\Local\\Temp\\ipykernel_10044\\3753786471.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\campusseven02\\AppData\\Local\\Temp\\ipykernel_10044\\3753786471.py:27: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "loss value : 1072.21826171875\n",
      "loss value : 1.074231743812561\n",
      "loss value : 0.66689133644104\n",
      "loss value : 0.5257416367530823\n",
      "loss value : 0.4586733877658844\n",
      "loss value : 0.4299987554550171\n",
      "loss value : 0.4145071804523468\n",
      "loss value : 0.40369462966918945\n",
      "loss value : 0.3952553868293762\n",
      "loss value : 0.3879354000091553\n"
     ]
    }
   ],
   "source": [
    "# 위의 데이터를 이용해서 이번에는 Tensorflow를 이용해 구현해 보아요!\n",
    "import tensorflow as tf\n",
    "\n",
    "## tensorflow 그래프를 그려보아요!\n",
    "\n",
    "## placeholder\n",
    "X = tf.placeholder(shape=[None,30], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([30,1]))\n",
    "b = tf.Variable(tf.random.normal([1]))\n",
    "\n",
    "# Hypothesis, model, predict model, Logistic Regression Model\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# cross entropy(loss function)\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                              labels=T))\n",
    "\n",
    "# train \n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-4).minimize(loss)\n",
    "\n",
    "# Session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())   # 초기화 작업.\n",
    "\n",
    "# 반복학습\n",
    "# 전체 데이터를 이용해서 1번 학습 => 1 epoch(에폭)\n",
    "for step in range(100000):\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X: train_x_data,\n",
    "                                                     T: train_t_data.reshape(-1,1)})\n",
    "    if step % 10000 == 0:\n",
    "        print('loss value : {}'.format(loss_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9c39f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 57\n",
      "Accuracy : 0.9035087823867798\n"
     ]
    }
   ],
   "source": [
    "# 정확도(accuracy) 측정\n",
    "\n",
    "# validation data(test_x_data, test_t_data)를 이용해서 정확도를 측정\n",
    "predict = tf.cast(H >= 0.5, dtype=tf.float32)   # True -> 1.0\n",
    "                                                # False -> 0.0 \n",
    "correct = tf.equal(predict, T)     # True, False, False, True, ...  \n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32)) #   1  , 0   ,  0   ,  1\n",
    "\n",
    "accuracy_val = sess.run(accuracy, feed_dict={X: test_x_data,\n",
    "                                             T: test_t_data.reshape(-1,1)})\n",
    "print('Accuracy : {}'.format(accuracy_val))  # 0.9035087823867798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a57b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번째 titanic 예제를 이용해서 Logistic Regression을 구현해 보아요!\n",
    "# Kaggle에서 데이터셋을 받아서 나온 결과를 Kaggle에 upload해서 우리 모델의\n",
    "# 정확도를 평가받아 보아요!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-machine_TF15] *",
   "language": "python",
   "name": "conda-env-.conda-machine_TF15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
